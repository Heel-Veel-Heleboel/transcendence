input {
  # Receive logs from Filebeat
  beats {
    port => 5044
    ssl => true
    ssl_certificate => "/usr/share/logstash/certs/logstash/logstash.crt"
    ssl_key => "/usr/share/logstash/certs/logstash/logstash.key"
    ssl_certificate_authorities => ["/usr/share/logstash/certs/ca/ca.crt"]
    # TODO: Implement proper client certificates - currently using optional for flexibility
    ssl_client_authentication => "optional"
  }
}

filter {
  # Handle Filebeat's service field if it exists as an object
  if [service][type] {
    mutate {
      add_field => { "service_name" => "%{[service][type]}" }
    }
  }

  # Extract service name from Docker container name
  # Filebeat adds container.name (e.g., "transcendence-api-gateway-1")
  if [container][name] and ![service_name] {
    grok {
      match => { "[container][name]" => "^transcendence-(?<service_name>[a-zA-Z0-9_-]+)-\d+$" }
      tag_on_failure => ["_grokparsefailure_container_name"]
    }
  }

  # Fallback: use hostname if service not extracted
  if ![service_name] and [hostname] {
    mutate {
      add_field => { "service_name" => "%{hostname}" }
    }
  }

  # Parse JSON log message if it exists
  # Let JSON filter fail gracefully instead of using regex pre-check
  json {
    source => "message"
    target => "log_data"
    skip_on_invalid_json => true
    tag_on_failure => ["_jsonparsefailure"]
  }

  # Copy parsed fields to root level and handle timestamp
  if [log_data][level] {
    mutate {
      add_field => { "level" => "%{[log_data][level]}" }
    }
  }

  # Use application's original timestamp if available
  if [log_data][time] {
    date {
      match => [ "[log_data][time]", "UNIX_MS" ]
      target => "@timestamp"
    }
  }

  # Add severity level based on Pino level
  if [level] {
    if [level] >= 50 {
      mutate {
        add_field => { "severity" => "error" }
      }
    } else if [level] >= 40 {
      mutate {
        add_field => { "severity" => "warn" }
      }
    } else if [level] >= 30 {
      mutate {
        add_field => { "severity" => "info" }
      }
    } else {
      mutate {
        add_field => { "severity" => "debug" }
      }
    }
  }

  # Remove duplicate @timestamp from log_data to prevent conflicts
  if [log_data][@timestamp] {
    mutate {
      remove_field => [ "[log_data][@timestamp]" ]
    }
  }

  # Remove original message after successful JSON parsing to save space
  # The data is now in log_data, so message is redundant
  if [log_data] and "_jsonparsefailure" not in [tags] {
    mutate {
      remove_field => [ "message", "[event][original]" ]
    }
  }

  # Remove verbose Docker metadata to reduce index size
  # Keep only essential container identification fields
  mutate {
    remove_field => [
      "[container][labels]",
      "[docker][container][labels]",
      "[agent]",
      "[log][file]",
      "[log][offset]",
      "[input]",
      "[ecs]",
      "[host][name]",
      "hostname",
      "stream"
    ]
  }

  # Determine index name based on service
  if [service_name] and [service_name] != "" {
    mutate {
      add_field => {
        "[@metadata][index_name]" => "logs-%{service_name}-%{+YYYY.MM.dd}"
      }
    }
  } else {
    mutate {
      add_field => {
        "[@metadata][index_name]" => "logs-unknown-%{+YYYY.MM.dd}"
      }
    }
  }
}

output {
  elasticsearch {
    hosts => ["${ELASTIC_HOSTS}"]
    user => "${ELASTIC_USER}"
    password => "${ELASTIC_PASSWORD}"
    ssl_certificate_authorities => ["/usr/share/logstash/certs/ca/ca.crt"]

    index => "%{[@metadata][index_name]}"
    action => "create"
  }

  # Debug output - see what Logstash receives and sends
  # Enable only when LOGSTASH_DEBUG is set to "true"
  if "${LOGSTASH_DEBUG}" == "true" {
    stdout {
      codec => rubydebug
    }
  }
}
