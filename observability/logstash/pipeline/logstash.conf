input {
  # Receive logs from Filebeat
  beats {
    port => 5044
    ssl => true
    ssl_certificate => "/usr/share/logstash/certs/logstash/logstash.crt"
    ssl_key => "/usr/share/logstash/certs/logstash/logstash.key"
    ssl_certificate_authorities => ["/usr/share/logstash/certs/ca/ca.crt"]
    ssl_client_authentication => "required"
  }
}

filter {
  # Handle Filebeat's service field if it exists as an object
  if [service][type] {
    mutate {
      add_field => { "service_name" => "%{[service][type]}" }
    }
  }

  # Extract service name from Docker container name
  # Expected naming convention: "transcendence-<service_name>-<number>"
  # Example from Filebeat: container.name = "transcendence-api-gateway-1"
  if [container][name] and ![service_name] {
    grok {
      match => { "[container][name]" => "^transcendence-(?<service_name>[a-zA-Z0-9_-]+)-\d+$" }
      tag_on_failure => ["_grokparsefailure_container_name"]
    }

    # If the container name does not match the expected pattern, add an explicit tag and field
    if "_grokparsefailure_container_name" in [tags] {
      mutate {
        add_tag => ["container_name_pattern_mismatch"]
        add_field => { "container_name_parse_error" => "Unexpected container.name format: %{[container][name]}" }
      }
    }
  }

  # Fallback: use hostname if service not extracted
  if ![service_name] and [hostname] {
    mutate {
      add_field => { "service_name" => "%{hostname}" }
    }
  }

  # Parse JSON log message if it exists
  # Let JSON filter fail gracefully instead of using regex pre-check
  json {
    source => "message"
    target => "log_data"
    skip_on_invalid_json => true
    tag_on_failure => ["_jsonparsefailure"]
  }

  # Copy parsed fields to root level
  if [log_data] {
    # Use application's original timestamp if available
    if [log_data][time] {
      date {
        match => [ "[log_data][time]", "UNIX_MS" ]
        target => "@timestamp"
      }
    }

    # Copy level field to root
    if [log_data][level] {
      mutate {
        add_field => { "level" => "%{[log_data][level]}" }
      }
    }
  }

  # Add severity level based on Pino level
  if [level] {
    if [level] >= 50 {
      mutate {
        add_field => { "severity" => "error" }
      }
    } else if [level] >= 40 {
      mutate {
        add_field => { "severity" => "warn" }
      }
    } else if [level] >= 30 {
      mutate {
        add_field => { "severity" => "info" }
      }
    } else {
      mutate {
        add_field => { "severity" => "debug" }
      }
    }
  }

  # Remove duplicate @timestamp from log_data to prevent conflicts
  if [log_data][@timestamp] {
    mutate {
      remove_field => [ "[log_data][@timestamp]" ]
    }
  }

  # Remove verbose Docker metadata to reduce index size
  # Keep only essential container identification fields
  mutate {
    remove_field => [
      "[container][labels]",
      "[docker][container][labels]",
      "[agent]",
      "[log][file]",
      "[log][offset]",
      "[input]",
      "[ecs]",
      "[host][name]",
      "hostname",
      "stream"
    ]
  }

  # Determine index name based on service
  if [service_name] and [service_name] != "" {
    mutate {
      add_field => {
        "[@metadata][index_name]" => "logs-%{service_name}-%{+YYYY.MM.dd}"
      }
    }
  } else {
    mutate {
      add_field => {
        "[@metadata][index_name]" => "logs-unknown-%{+YYYY.MM.dd}"
      }
    }
  }
}

output {
  elasticsearch {
    hosts => ["${ELASTIC_HOSTS}"]
    user => "${ELASTIC_USER}"
    password => "${ELASTIC_PASSWORD}"
    ssl_certificate_authorities => ["/usr/share/logstash/certs/ca/ca.crt"]

    index => "%{[@metadata][index_name]}"
    action => "index"
  }

  # Debug output - see what Logstash receives and sends
  # Enable only when LOGSTASH_DEBUG is set to "true"
  if "${LOGSTASH_DEBUG}" == "true" {
    stdout {
      codec => rubydebug
    }
  }
}
